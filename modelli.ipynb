{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modelli.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielecaliari/AML/blob/main/modelli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGu1cWhwUmVp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import sparse\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCfT6ih7UxsY",
        "outputId": "b31cef2a-b82f-4490-b82e-36bef498c3bd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "root_dir = \"/content/drive/MyDrive/\"\n",
        "base_dir = root_dir + 'progetto_AML/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0zNqv_cjeLu"
      },
      "source": [
        "\n",
        "label = pd.read_csv(base_dir + 'label.csv')\n",
        "label = label['price'].values"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LSSfeTbwws9"
      },
      "source": [
        "Regression without embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q8YsEuJUyYc"
      },
      "source": [
        "from scipy import sparse\n",
        "train = sparse.load_npz(base_dir + 'train.npz')\n",
        "test = sparse.load_npz(base_dir + 'test.npz')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FByxOA4jvKkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11ebbd14-e13e-4a54-8704-1f4ddbd0024b"
      },
      "source": [
        "label.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1481661,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mozGIzyVMQX"
      },
      "source": [
        "def create_mlp(dim):\n",
        "\t# define our MLP network\n",
        "  model = Sequential()\n",
        "  model.add(Dense(256, input_dim=dim, activation=\"relu\"))\n",
        "  model.add(Dense(128, activation=\"relu\"))\n",
        "  model.add(Dense(64, activation=\"relu\"))\n",
        "  model.add(Dense(1, activation=\"linear\"))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTKhUuHsWg3T"
      },
      "source": [
        "Split in training & validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkfJBVWKV4hg"
      },
      "source": [
        "(train, validation, label_train, label_validation) = train_test_split(train , label , test_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_CNW5U2XHUu",
        "outputId": "966f960e-5f09-4412-9f93-73090e7cc325"
      },
      "source": [
        "validation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<370416x45811 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 12798615 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQE3lBA8XJ4C",
        "outputId": "fb581908-484b-419a-b562-4d3dedcae65e"
      },
      "source": [
        "train.shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45811"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1L3zVBaWgE8"
      },
      "source": [
        "model = create_mlp(train.shape[1])\n",
        "model.compile(loss=\"mean_squared_logarithmic_error\")\n",
        "model.fit(x=train, y=label_train, validation_data=(validation, label_validation), epochs=20, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fso9o50EYoa2"
      },
      "source": [
        "Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7NHFxSIXWeu"
      },
      "source": [
        "preds = model.predict(test)\n",
        "# fare inversa log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O9QrvRpZ_sH"
      },
      "source": [
        "Word embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z2xSMribc8o"
      },
      "source": [
        "train_emb = sparse.load_npz(base_dir + 'train_emb.npz')\n",
        "test_emb = sparse.load_npz(base_dir + 'test_emb.npz')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSLPY2DHx-Kn"
      },
      "source": [
        "train = pd.read_csv(base_dir + 'train.tsv', sep='\\t')\n",
        "test = pd.read_csv(base_dir + 'test.tsv', sep='\\t')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ8QNLy5-3pa"
      },
      "source": [
        "train = train[train['price']>0].reset_index(drop=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57Czj6UPpD4V"
      },
      "source": [
        "train.item_description=train.item_description.astype(str)\n",
        "test.item_description=test.item_description.astype(str)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBZkd90ScIyb"
      },
      "source": [
        "train_names = train['name']\n",
        "train_descriptions = train['item_description']\n",
        "\n",
        "train_names_test = train['name']\n",
        "train_descriptions_test = train['item_description']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R-HYHg2yoA5"
      },
      "source": [
        "(train_emb, validation_emb, label_train_emb, label_validation_emb) = train_test_split(train_emb , label , test_size=0.25, shuffle= False)\n",
        "(train_names, train_names_validation) = train_test_split(train_names, test_size=0.25, shuffle= False)\n",
        "(train_descriptions, train_descriptions_validation) = train_test_split(train_descriptions, test_size=0.25, shuffle= False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Pi-AHWBcUk4",
        "outputId": "55320a8e-ad16-4b8d-a6d5-e3f58b49e096"
      },
      "source": [
        "train_names"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0            MLB Cincinnati Reds T Shirt Size XL\n",
              "1               Razer BlackWidow Chroma Keyboard\n",
              "2                                 AVA-VIV Blouse\n",
              "3                          Leather Horse Statues\n",
              "4                           24K GOLD plated rose\n",
              "                           ...                  \n",
              "1111896                    Pink Timberland Boots\n",
              "1111897              Lose fat weight with acxion\n",
              "1111898    New Victoria's Secret mesh tights. XS\n",
              "1111899                          Gap deer outfit\n",
              "1111900            Women's Miss Me jeans size 28\n",
              "Name: name, Length: 1111901, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk8XffKNcgsq"
      },
      "source": [
        "names = []\n",
        "for n in train_names:\n",
        "  names.append(n)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nsSZSlLk17S"
      },
      "source": [
        "descriptions = []\n",
        "for n in train_descriptions:\n",
        "  descriptions.append(n)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn2hflhEiDg1",
        "outputId": "21929923-9f66-4f5c-e56c-ab8fe25bc75b"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(nb_words=100000)\n",
        "tokenizer.fit_on_texts(names)\n",
        "sequences = tokenizer.texts_to_sequences(names)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "names_data = pad_sequences(sequences, maxlen=20)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/text.py:180: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 100802 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nzjd7-Ioqsj",
        "outputId": "dc9f520b-d243-4f32-88ee-d313397a5761"
      },
      "source": [
        "tokenizer = Tokenizer(nb_words=100000)\n",
        "tokenizer.fit_on_texts(descriptions)\n",
        "sequences = tokenizer.texts_to_sequences(descriptions)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "descriptions_data = pad_sequences(sequences, maxlen=20)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/text.py:180: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 178020 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1gHv9s3ha4j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5fUXcm_-Na6",
        "outputId": "665983fd-8614-45ac-811c-07374adde13a"
      },
      "source": [
        "train_emb.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1111245, 5811)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwrQ3GPj-SgC",
        "outputId": "a2e6316c-3048-4141-ef19-aa1067add587"
      },
      "source": [
        "descriptions_data.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1111245, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-QUO8hZCuNE"
      },
      "source": [
        "model = Sequential()\n",
        "  model.add(Dense(256, input_dim=dim, activation=\"relu\"))\n",
        "  model.add(Dense(128, activation=\"relu\"))\n",
        "  model.add(Dense(64, activation=\"relu\"))\n",
        "  model.add(Dense(1, activation=\"linear\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPjgdQoqaBR6"
      },
      "source": [
        "from tensorflow import keras\n",
        "num_words_name = 100802  # Size of vocabulary obtained when preprocessing text data\n",
        "num_words_description = 178020  # Size of vocabulary obtained when preprocessing text data\n",
        "\n",
        "\n",
        "name_input = keras.Input(shape=(None,), name=\"name\")  # Variable-length sequence of ints\n",
        "description_input = keras.Input(shape=(None,), name=\"description\")  # Variable-length sequence of ints\n",
        "other_features_input = keras.Input(shape=(train_emb.shape[0],train_emb.shape[1]), name=\"other_features_input\")\n",
        "\n",
        "# Embed each word in the title into a 64-dimensional vector\n",
        "name_features = keras.layers.Embedding(num_words_name, 32)(name_input)\n",
        "# Embed each word in the text into a 64-dimensional vector\n",
        "description_features = keras.layers.Embedding(num_words_description, 64)(description_input)\n",
        "\n",
        "other_features_relu = keras.layers.Dense(128, activation=\"relu\")(other_features_input)\n",
        "\n",
        "# Merge all available features into a single large vector via concatenation\n",
        "x = keras.layers.concatenate([name_features, description_features, other_features_relu])\n",
        "\n",
        "\n",
        "# Stick a logistic regression for priority prediction on top of the features\n",
        "price_pred = keras.layers.Dense(1, activation=\"linear\", name=\"price\")(x)\n",
        "\n",
        "# Instantiate an end-to-end model predicting both priority and department\n",
        "model = keras.Model(\n",
        "    inputs=[name_input, description_input, other_features_input],\n",
        "    outputs=[price_pred],\n",
        ")"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPxnB2IyrLgi"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
        "    loss={\n",
        "        \"price\": keras.losses.MeanSquaredLogarithmicError,\n",
        "    },\n",
        "    loss_weights=[1.0],\n",
        ")"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "id": "Sksq585frgkj",
        "outputId": "436f1e1a-ea93-4869-9e0e-4ad262c8c941"
      },
      "source": [
        "model.fit(\n",
        "    {\"name\": names_data, \"description\": descriptions_data, \"other_features_input\": train_emb},\n",
        "    {\"price\": label_train_emb},\n",
        "    validation_data=(train_names_validation, train_descriptions_validation, validation_emb, label_validation_emb),\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        ")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-126dacb087c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_names_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_descriptions_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_validation_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m       val_x, val_y, val_sample_weight = (\n\u001b[0;32m-> 1045\u001b[0;31m           data_adapter.unpack_x_y_sample_weight(validation_data))\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36munpack_x_y_sample_weight\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1452\u001b[0m     error_msg = (\"Data is expected to be in format `x`, `(x,)`, `(x, y)`, \"\n\u001b[1;32m   1453\u001b[0m                  \"or `(x, y, sample_weight)`, found: {}\").format(data)\n\u001b[0;32m-> 1454\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data is expected to be in format `x`, `(x,)`, `(x, y)`, or `(x, y, sample_weight)`, found: (1111245                 Men's Adidas Quarter Zip\n1111246                         Bakugan Toys Lot\n1111247           Supreme x New Era Big S Beanie\n1111248            Camel gold cowl sweater dress\n1111249                   Air Jordan 4 Cool Grey\n                           ...                  \n1481656               Free People Inspired Dress\n1481657            Little mermaid handmade dress\n1481658    21 day fix containers and eating plan\n1481659                   World markets lanterns\n1481660            Brand new lux de ville wallet\nName: name, Length: 370416, dtype: object, 1111245                                   No description yet\n1111246    First picture is of flawed Bakugans (broken or...\n1111247    Supreme x New Era Big S beanie. Black box logo...\n1111248    **PLEASE ASK ANY QUESTIONS BEFORE PURCHASING (...\n1111249    Shoes are in decent condition need to be resto...\n                                 ...                        \n1481656    Lace, says size small but fits medium perfectl...\n1481657     Little mermaid handmade dress never worn size 2t\n1481658            Used once or twice, still in great shape.\n1481659    There is 2 of each one that you see! So 2 red ...\n1481660    New with tag, red with sparkle. Firm price, no...\nName: item_description, Length: 370416, dtype: object, <370416x5811 sparse matrix of type '<class 'numpy.float64'>'\n\twith 3556303 stored elements in Compressed Sparse Row format>, array([3.09104245, 2.77258872, 3.58351894, ..., 2.56494936, 3.8286414 ,\n       3.13549422]))"
          ]
        }
      ]
    }
  ]
}